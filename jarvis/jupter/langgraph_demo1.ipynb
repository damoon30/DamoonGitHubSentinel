{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-08-25T15:32:52.388718Z",
     "start_time": "2024-08-25T15:32:50.401503Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m24.0\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m24.2\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "source": [
    "import functools\n",
    "!pip install -q -U langchain-openai langgraph langchain"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n",
      "[{'url': 'https://www.weatherapi.com/', 'content': \"{'location': {'name': 'San Francisco', 'region': 'California', 'country': 'United States of America', 'lat': 37.78, 'lon': -122.42, 'tz_id': 'America/Los_Angeles', 'localtime_epoch': 1724599840, 'localtime': '2024-08-25 08:30'}, 'current': {'last_updated_epoch': 1724599800, 'last_updated': '2024-08-25 08:30', 'temp_c': 17.2, 'temp_f': 63.0, 'is_day': 1, 'condition': {'text': 'Partly cloudy', 'icon': '//cdn.weatherapi.com/weather/64x64/day/116.png', 'code': 1003}, 'wind_mph': 2.2, 'wind_kph': 3.6, 'wind_degree': 10, 'wind_dir': 'N', 'pressure_mb': 1021.0, 'pressure_in': 30.14, 'precip_mm': 0.0, 'precip_in': 0.0, 'humidity': 87, 'cloud': 25, 'feelslike_c': 17.2, 'feelslike_f': 63.0, 'windchill_c': 16.0, 'windchill_f': 60.7, 'heatindex_c': 15.9, 'heatindex_f': 60.5, 'dewpoint_c': 11.6, 'dewpoint_f': 52.8, 'vis_km': 16.0, 'vis_miles': 9.0, 'uv': 5.0, 'gust_mph': 3.8, 'gust_kph': 6.0}}\"}, {'url': 'https://www.weathertab.com/en/c/e/08/united-states/california/san-francisco/', 'content': 'Avg Low Temps 50 to 60 Â°F. Explore comprehensive August 2024 weather forecasts for San Francisco, including daily high and low temperatures, precipitation risks, and monthly temperature trends. Featuring detailed day-by-day forecasts, dynamic graphs of daily rain probabilities, and temperature trends to help you plan ahead.'}]\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "import os\n",
    "os.environ['TAVILY_API_KEY']=\"tvly-AIAghtTeT\"\n",
    "os.environ['LANGCHAIN_API_KEY']=\"lsv2_pt_45936eaf6b3972\"\n",
    "\n",
    "print(os.environ['TAVILY_API_KEY'])\n",
    "# print(os.environ['TAVILY_API_KEY'])\n",
    "search =  TavilySearchResults(max_results = 2, TAVILY_API_KEY=os.environ['TAVILY_API_KEY'])\n",
    "search_results = search.invoke(\"what is the weather in SF\")\n",
    "print(search_results)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-25T15:33:38.866685Z",
     "start_time": "2024-08-25T15:33:34.264911Z"
    }
   },
   "id": "59ae2ca5727e2b85",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor, create_openai_tools_agent\n",
    "from langchain_core.messages import BaseMessage, HumanMessage\n",
    "from langchain.output_parsers.openai_functions import JsonKeyOutputFunctionsParser\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain.tools import tool\n",
    "from langchain_openai import ChatOpenAI\n",
    "from typing import Annotated, Any, Dict, List, Optional, Sequence, TypedDict"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-25T16:50:03.920934Z",
     "start_time": "2024-08-25T16:50:03.917410Z"
    }
   },
   "id": "fe3611bc2e1be9b3",
   "execution_count": 36
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model = \"gpt-4o-mini\") "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-25T16:50:04.902820Z",
     "start_time": "2024-08-25T16:50:04.851397Z"
    }
   },
   "id": "d8ad0bfbb4977763",
   "execution_count": 37
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from langchain_core.messages import (\n",
    "BaseMessage, HumanMessage,AIMessage, ChatMessage, FunctionMessage, SystemMessage\n",
    ")\n",
    "@tool(\"web_search\")\n",
    "def web_search(query: str)-> str :\n",
    "    \"\"\"search with api\"\"\"\n",
    "    search = TavilySearchResults(max_results =2)\n",
    "    return search.invoke(query)\n",
    "\n",
    "@tool(\"twitter_writer\")\n",
    "def write_tweet(content: str) -> str:\n",
    "    \"\"\"Base on a piece content, write a tweet\"\"\"\n",
    "    chat = ChatOpenAI(model = \"gpt-4o-mini\") \n",
    "    message = [\n",
    "        SystemMessage(content=\"you are a Twitter account operator. you are responsible for writing a tweet base on the content given. you should fellow the twitter policy and make sure the twitter nno more than 1400 characters\"),\n",
    "        HumanMessage(content=content)\n",
    "    ]\n",
    "    response = chat.invoke(message)\n",
    "    return response.content"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-25T16:50:08.646383Z",
     "start_time": "2024-08-25T16:50:08.636137Z"
    }
   },
   "id": "f4e28cdabaf5f5c9",
   "execution_count": 38
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import operator\n",
    "\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    # the Annotated tell the graph that the messages will always be added to the current states\n",
    "    messages: Annotated[Sequence[BaseMessage], operator.add]\n",
    "    # the next field indicates where to route to next\n",
    "    next: str"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-25T16:50:10.678272Z",
     "start_time": "2024-08-25T16:50:10.674477Z"
    }
   },
   "id": "1ed4674eb8c9ff1c",
   "execution_count": 39
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def create_agent(llm: ChatOpenAI, tools: list, system_message: SystemMessage):\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", system_message),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "    ])\n",
    "    agent = create_openai_tools_agent(llm, tools, prompt)\n",
    "    executor = AgentExecutor(agent=agent, tools=tools)\n",
    "    return executor"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-25T16:50:11.806873Z",
     "start_time": "2024-08-25T16:50:11.803301Z"
    }
   },
   "id": "5acc0ff50374c331",
   "execution_count": 40
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def create_node(state: AgentState, agent, name):\n",
    "    result = agent.invoke(state)\n",
    "    return {\"messages\": [HumanMessage(content=result[\"output\"], name=name)]}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-25T16:50:12.737186Z",
     "start_time": "2024-08-25T16:50:12.735376Z"
    }
   },
   "id": "16b6e787621e5685",
   "execution_count": 41
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "members = [\"Search_Engine\", \"Twitter_Writer\"]\n",
    "system_prompt = \"You are a supervisor tasked with managing a conversation between the following workers: {members}. Given the following user request, respond with the worker to act next. Each worker will perform a task and respond with their results and status. When finished, respond with FINISH.\"\n",
    "\n",
    "options = [\"FINISH\"] + members\n",
    "# use openai function calling can make output parser easier for us\n",
    "function_def = {\n",
    "    \"name\": \"route\",\n",
    "    \"description\": \"Select the next role.\",\n",
    "    \"parameters\": {\n",
    "        \"title\":\"routeSchema\",\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"next\": {\n",
    "                \"title\":\"Next\",\n",
    "                \"anyof\": [\n",
    "                    {\"enum\": options}\n",
    "                ]\n",
    "            }\n",
    "        },\n",
    "        \"require\": [\"next\"],\n",
    "    },\n",
    "}\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "        (\n",
    "            \"system\", \n",
    "            \"Given the conversion above, who should act next or should we FINISH? select one of : {options}\"\n",
    "        ),\n",
    "    ]\n",
    ").partial(options=str(options), members=\", \".join(members))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-25T16:50:14.646400Z",
     "start_time": "2024-08-25T16:50:14.641445Z"
    }
   },
   "id": "e9919932ca13298",
   "execution_count": 42
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "supervisor_chain = (\n",
    "    prompt\n",
    "    | llm.bind_functions(functions=[function_def], function_call=\"route\")\n",
    "    | JsonKeyOutputFunctionsParser\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-25T16:50:16.630891Z",
     "start_time": "2024-08-25T16:50:16.627248Z"
    }
   },
   "id": "69243f65b4c2456a",
   "execution_count": 43
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "search_engine_agent = create_agent(llm, [web_search], \"you are a web search engine\")\n",
    "search_engine_node = partial(create_node, agent=search_engine_agent, name=\"Search_Engine\")\n",
    "\n",
    "\n",
    "twitter_operate_agent = create_agent(llm, [write_tweet], \"you are responsible for writing a tweet base on the content given\")\n",
    "twitter_operate_node = partial(create_node, agent=twitter_operate_agent, name=\"Twitter_Writer\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-25T16:50:17.583192Z",
     "start_time": "2024-08-25T16:50:17.576105Z"
    }
   },
   "id": "6f854e893c127a12",
   "execution_count": 44
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Search_Engine': 'Search_Engine', 'Twitter_Writer': 'Twitter_Writer', 'FINISH': '__end__'}\n"
     ]
    }
   ],
   "source": [
    "workflow = StateGraph(AgentState)\n",
    "workflow.add_node(\"Search_Engine\", search_engine_node)\n",
    "workflow.add_node(\"Twitter_Writer\", twitter_operate_node)\n",
    "workflow.add_node(\"supervisor\", supervisor_chain)\n",
    "\n",
    "for member in members:\n",
    "    workflow.add_edge(member, \"supervisor\")\n",
    "    \n",
    "conditional_map = {k: k for k in members}\n",
    "conditional_map[\"FINISH\"]=END\n",
    "print(conditional_map)\n",
    "workflow.add_conditional_edges(\"supervisor\", lambda x:x[\"next\"], conditional_map)\n",
    "\n",
    "workflow.set_entry_point(\"supervisor\")\n",
    "\n",
    "graph = workflow.compile()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-25T16:50:18.344138Z",
     "start_time": "2024-08-25T16:50:18.338571Z"
    }
   },
   "id": "1891a81adfbae1c",
   "execution_count": 45
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "BaseModel.__init__() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[48], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43ms\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mgraph\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstream\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m      2\u001B[0m \u001B[43m        \u001B[49m\u001B[43m{\u001B[49m\n\u001B[1;32m      3\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmessages\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\n\u001B[1;32m      4\u001B[0m \u001B[43m                \u001B[49m\u001B[43mHumanMessage\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcontent\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mwrite a tweet about langchain news\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      5\u001B[0m \u001B[43m            \u001B[49m\u001B[43m]\u001B[49m\n\u001B[1;32m      6\u001B[0m \u001B[43m        \u001B[49m\u001B[43m}\u001B[49m\n\u001B[1;32m      7\u001B[0m \u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\n\u001B[1;32m      8\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m__end__\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43ms\u001B[49m\u001B[43m:\u001B[49m\n\u001B[1;32m      9\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mprint\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43ms\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/classProject/DamoonGitHubSentinel/.venv/lib/python3.12/site-packages/langgraph/pregel/__init__.py:1020\u001B[0m, in \u001B[0;36mPregel.stream\u001B[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug)\u001B[0m\n\u001B[1;32m   1017\u001B[0m         \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[1;32m   1019\u001B[0m \u001B[38;5;66;03m# panic on failure or timeout\u001B[39;00m\n\u001B[0;32m-> 1020\u001B[0m \u001B[43m_panic_or_proceed\u001B[49m\u001B[43m(\u001B[49m\u001B[43mall_futures\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mloop\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstep\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1021\u001B[0m \u001B[38;5;66;03m# don't keep futures around in memory longer than needed\u001B[39;00m\n\u001B[1;32m   1022\u001B[0m \u001B[38;5;28;01mdel\u001B[39;00m done, inflight, futures\n",
      "File \u001B[0;32m~/classProject/DamoonGitHubSentinel/.venv/lib/python3.12/site-packages/langgraph/pregel/__init__.py:1450\u001B[0m, in \u001B[0;36m_panic_or_proceed\u001B[0;34m(futs, step, timeout_exc_cls)\u001B[0m\n\u001B[1;32m   1448\u001B[0m             inflight\u001B[38;5;241m.\u001B[39mpop()\u001B[38;5;241m.\u001B[39mcancel()\n\u001B[1;32m   1449\u001B[0m         \u001B[38;5;66;03m# raise the exception\u001B[39;00m\n\u001B[0;32m-> 1450\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m exc\n\u001B[1;32m   1452\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m inflight:\n\u001B[1;32m   1453\u001B[0m     \u001B[38;5;66;03m# if we got here means we timed out\u001B[39;00m\n\u001B[1;32m   1454\u001B[0m     \u001B[38;5;28;01mwhile\u001B[39;00m inflight:\n\u001B[1;32m   1455\u001B[0m         \u001B[38;5;66;03m# cancel all pending tasks\u001B[39;00m\n",
      "File \u001B[0;32m~/classProject/DamoonGitHubSentinel/.venv/lib/python3.12/site-packages/langgraph/pregel/executor.py:60\u001B[0m, in \u001B[0;36mBackgroundExecutor.done\u001B[0;34m(self, task)\u001B[0m\n\u001B[1;32m     58\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdone\u001B[39m(\u001B[38;5;28mself\u001B[39m, task: concurrent\u001B[38;5;241m.\u001B[39mfutures\u001B[38;5;241m.\u001B[39mFuture) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m     59\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 60\u001B[0m         \u001B[43mtask\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mresult\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     61\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m GraphInterrupt:\n\u001B[1;32m     62\u001B[0m         \u001B[38;5;66;03m# This exception is an interruption signal, not an error\u001B[39;00m\n\u001B[1;32m     63\u001B[0m         \u001B[38;5;66;03m# so we don't want to re-raise it on exit\u001B[39;00m\n\u001B[1;32m     64\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtasks\u001B[38;5;241m.\u001B[39mpop(task)\n",
      "File \u001B[0;32m/opt/homebrew/Cellar/python@3.12/3.12.4/Frameworks/Python.framework/Versions/3.12/lib/python3.12/concurrent/futures/_base.py:449\u001B[0m, in \u001B[0;36mFuture.result\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    447\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m CancelledError()\n\u001B[1;32m    448\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_state \u001B[38;5;241m==\u001B[39m FINISHED:\n\u001B[0;32m--> 449\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m__get_result\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    451\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_condition\u001B[38;5;241m.\u001B[39mwait(timeout)\n\u001B[1;32m    453\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_state \u001B[38;5;129;01min\u001B[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001B[0;32m/opt/homebrew/Cellar/python@3.12/3.12.4/Frameworks/Python.framework/Versions/3.12/lib/python3.12/concurrent/futures/_base.py:401\u001B[0m, in \u001B[0;36mFuture.__get_result\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    399\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_exception:\n\u001B[1;32m    400\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 401\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_exception\n\u001B[1;32m    402\u001B[0m     \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m    403\u001B[0m         \u001B[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001B[39;00m\n\u001B[1;32m    404\u001B[0m         \u001B[38;5;28mself\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m/opt/homebrew/Cellar/python@3.12/3.12.4/Frameworks/Python.framework/Versions/3.12/lib/python3.12/concurrent/futures/thread.py:58\u001B[0m, in \u001B[0;36m_WorkItem.run\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     55\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m\n\u001B[1;32m     57\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 58\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     59\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m exc:\n\u001B[1;32m     60\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfuture\u001B[38;5;241m.\u001B[39mset_exception(exc)\n",
      "File \u001B[0;32m~/classProject/DamoonGitHubSentinel/.venv/lib/python3.12/site-packages/langgraph/pregel/retry.py:26\u001B[0m, in \u001B[0;36mrun_with_retry\u001B[0;34m(task, retry_policy)\u001B[0m\n\u001B[1;32m     24\u001B[0m task\u001B[38;5;241m.\u001B[39mwrites\u001B[38;5;241m.\u001B[39mclear()\n\u001B[1;32m     25\u001B[0m \u001B[38;5;66;03m# run the task\u001B[39;00m\n\u001B[0;32m---> 26\u001B[0m \u001B[43mtask\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mproc\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minvoke\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtask\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minput\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtask\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     27\u001B[0m \u001B[38;5;66;03m# if successful, end\u001B[39;00m\n\u001B[1;32m     28\u001B[0m \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "File \u001B[0;32m~/classProject/DamoonGitHubSentinel/.venv/lib/python3.12/site-packages/langchain_core/runnables/base.py:2878\u001B[0m, in \u001B[0;36mRunnableSequence.invoke\u001B[0;34m(self, input, config, **kwargs)\u001B[0m\n\u001B[1;32m   2876\u001B[0m             \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m context\u001B[38;5;241m.\u001B[39mrun(step\u001B[38;5;241m.\u001B[39minvoke, \u001B[38;5;28minput\u001B[39m, config, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m   2877\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 2878\u001B[0m             \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[43mcontext\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstep\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minvoke\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2879\u001B[0m \u001B[38;5;66;03m# finish the root run\u001B[39;00m\n\u001B[1;32m   2880\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "File \u001B[0;32m~/classProject/DamoonGitHubSentinel/.venv/lib/python3.12/site-packages/langchain_core/runnables/base.py:4475\u001B[0m, in \u001B[0;36mRunnableLambda.invoke\u001B[0;34m(self, input, config, **kwargs)\u001B[0m\n\u001B[1;32m   4461\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Invoke this Runnable synchronously.\u001B[39;00m\n\u001B[1;32m   4462\u001B[0m \n\u001B[1;32m   4463\u001B[0m \u001B[38;5;124;03mArgs:\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   4472\u001B[0m \u001B[38;5;124;03m    TypeError: If the Runnable is a coroutine function.\u001B[39;00m\n\u001B[1;32m   4473\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   4474\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfunc\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m-> 4475\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_with_config\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   4476\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_invoke\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   4477\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m   4478\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_config\u001B[49m\u001B[43m(\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfunc\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   4479\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   4480\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   4481\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   4482\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\n\u001B[1;32m   4483\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCannot invoke a coroutine function synchronously.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   4484\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUse `ainvoke` instead.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   4485\u001B[0m     )\n",
      "File \u001B[0;32m~/classProject/DamoonGitHubSentinel/.venv/lib/python3.12/site-packages/langchain_core/runnables/base.py:1785\u001B[0m, in \u001B[0;36mRunnable._call_with_config\u001B[0;34m(self, func, input, config, run_type, **kwargs)\u001B[0m\n\u001B[1;32m   1781\u001B[0m     context \u001B[38;5;241m=\u001B[39m copy_context()\n\u001B[1;32m   1782\u001B[0m     context\u001B[38;5;241m.\u001B[39mrun(_set_config_context, child_config)\n\u001B[1;32m   1783\u001B[0m     output \u001B[38;5;241m=\u001B[39m cast(\n\u001B[1;32m   1784\u001B[0m         Output,\n\u001B[0;32m-> 1785\u001B[0m         \u001B[43mcontext\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1786\u001B[0m \u001B[43m            \u001B[49m\u001B[43mcall_func_with_variable_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# type: ignore[arg-type]\u001B[39;49;00m\n\u001B[1;32m   1787\u001B[0m \u001B[43m            \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# type: ignore[arg-type]\u001B[39;49;00m\n\u001B[1;32m   1788\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# type: ignore[arg-type]\u001B[39;49;00m\n\u001B[1;32m   1789\u001B[0m \u001B[43m            \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1790\u001B[0m \u001B[43m            \u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1791\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1792\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m,\n\u001B[1;32m   1793\u001B[0m     )\n\u001B[1;32m   1794\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m   1795\u001B[0m     run_manager\u001B[38;5;241m.\u001B[39mon_chain_error(e)\n",
      "File \u001B[0;32m~/classProject/DamoonGitHubSentinel/.venv/lib/python3.12/site-packages/langchain_core/runnables/config.py:397\u001B[0m, in \u001B[0;36mcall_func_with_variable_args\u001B[0;34m(func, input, config, run_manager, **kwargs)\u001B[0m\n\u001B[1;32m    395\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m run_manager \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m accepts_run_manager(func):\n\u001B[1;32m    396\u001B[0m     kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrun_manager\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m run_manager\n\u001B[0;32m--> 397\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/classProject/DamoonGitHubSentinel/.venv/lib/python3.12/site-packages/langchain_core/runnables/base.py:4331\u001B[0m, in \u001B[0;36mRunnableLambda._invoke\u001B[0;34m(self, input, run_manager, config, **kwargs)\u001B[0m\n\u001B[1;32m   4329\u001B[0m                 output \u001B[38;5;241m=\u001B[39m chunk\n\u001B[1;32m   4330\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 4331\u001B[0m     output \u001B[38;5;241m=\u001B[39m \u001B[43mcall_func_with_variable_args\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   4332\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\n\u001B[1;32m   4333\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   4334\u001B[0m \u001B[38;5;66;03m# If the output is a Runnable, invoke it\u001B[39;00m\n\u001B[1;32m   4335\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(output, Runnable):\n",
      "File \u001B[0;32m~/classProject/DamoonGitHubSentinel/.venv/lib/python3.12/site-packages/langchain_core/runnables/config.py:397\u001B[0m, in \u001B[0;36mcall_func_with_variable_args\u001B[0;34m(func, input, config, run_manager, **kwargs)\u001B[0m\n\u001B[1;32m    395\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m run_manager \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m accepts_run_manager(func):\n\u001B[1;32m    396\u001B[0m     kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrun_manager\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m run_manager\n\u001B[0;32m--> 397\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/classProject/DamoonGitHubSentinel/.venv/lib/python3.12/site-packages/langchain_core/load/serializable.py:113\u001B[0m, in \u001B[0;36mSerializable.__init__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    111\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs: Any, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    112\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\"\"\"\u001B[39;00m\n\u001B[0;32m--> 113\u001B[0m     \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__init__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mTypeError\u001B[0m: BaseModel.__init__() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "for s in graph.stream(\n",
    "        {\n",
    "            \"messages\": [\n",
    "                HumanMessage(content=\"write a tweet about langchain news\")\n",
    "            ]\n",
    "        }\n",
    "): \n",
    "    if \"__end__\" not in s:\n",
    "        print(s)\n",
    "        print(\"--------\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-25T16:51:49.588785Z",
     "start_time": "2024-08-25T16:51:48.633803Z"
    }
   },
   "id": "9f16bc964e02e876",
   "execution_count": 48
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "d98017e54556bbdb"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
